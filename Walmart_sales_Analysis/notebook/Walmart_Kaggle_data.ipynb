{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UepI9DafKgG_"
      },
      "outputs": [],
      "source": [
        "# load the mount the google drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the working folder in drive\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Python_learning/Walmart_dataset'"
      ],
      "metadata": {
        "id": "nNnm6oFZTRth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install the kaggle API for bringing data\n",
        "from google.colab import files\n",
        "import os\n",
        "# 1. Upload the kaggle.json file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 2. Create the .kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# 3. Set permissions so the API key isn't readable by others\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 4. Verify connection by listing datasets\n",
        "!kaggle datasets list"
      ],
      "metadata": {
        "id": "uHmAfwQNUCvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your destination path\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Python_learning/Walmart_dataset'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "# Download the dataset directly to that folder\n",
        "# The -p flag specifies the download directory\n",
        "!kaggle datasets download -d najir0123/walmart-10k-sales-datasets -p \"{path}\"\n",
        "\n",
        "# Unzip the file in that same location\n",
        "# Change to the directory first to keep things clean\n",
        "os.chdir(path)\n",
        "!unzip -o walmart-10k-sales-datasets.zip"
      ],
      "metadata": {
        "id": "X0zHPfiUWspw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading\n",
        "import pandas as pd\n",
        "df_walmart = pd.read_csv('Walmart.csv')\n",
        "df_walmart.head()"
      ],
      "metadata": {
        "id": "EoEWsWf4XzGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of the dataset\n",
        "df_walmart.shape"
      ],
      "metadata": {
        "id": "tm6qaBvog8Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# info of the dataset\n",
        "df_walmart.info()"
      ],
      "metadata": {
        "id": "NcyV5mcfg_E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stats for the datase\n",
        "df_walmart.describe()"
      ],
      "metadata": {
        "id": "Ka-VawIGhrf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "cu3Mv9Hih8q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find total number of duplicates\n",
        "df_walmart.duplicated().sum()\n",
        "\n",
        "# Remove duplicates\n",
        "df_walmart.drop_duplicates(inplace=True)\n",
        "\n",
        "# re check for number of duplicates\n",
        "df_walmart.duplicated().sum()"
      ],
      "metadata": {
        "id": "j2FwQcgchvVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find missing values\n",
        "df_walmart.isnull().sum()\n",
        "\n",
        "# drop the missing values\n",
        "df_walmart.dropna(inplace=True)\n",
        "\n",
        "# re check for missing values\n",
        "df_walmart.isnull().sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "KtOUP-ieiNOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of the dataframe\n",
        "df_walmart.shape"
      ],
      "metadata": {
        "id": "8R_u41u5iYi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the data type of unit_price to float after removing $ signs\n",
        "df_walmart['unit_price'] = df_walmart['unit_price'].str.replace('$', '').astype(float)\n",
        "\n",
        "# info for the dataframe\n",
        "df_walmart.info()"
      ],
      "metadata": {
        "id": "pMFIO0pnjI36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "5ngt4S5qkF4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a new column for total amount i.e unit_price * quantity\n",
        "df_walmart['total'] = df_walmart['unit_price'] * df_walmart['quantity']\n",
        "\n",
        "df_walmart.head()"
      ],
      "metadata": {
        "id": "0-eLFyMej0dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# handel date format, convert all in ISO format\n",
        "df_walmart['date'] = pd.to_datetime(df_walmart['date'])"
      ],
      "metadata": {
        "id": "G8oihllMutOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export the cleaned csv to\n",
        "df_walmart.to_csv('walmart_clean_data.csv', index=False)"
      ],
      "metadata": {
        "id": "9jNR4_ZNvifh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up file for pgSQL"
      ],
      "metadata": {
        "id": "HnOXu-u6oCKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install toolkits for pgSQL\n",
        "!pip install psycopg2-binary"
      ],
      "metadata": {
        "id": "1zRZTHi_lQqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to pgsql\n",
        "import psycopg2\n",
        "host = 'localhost'\n",
        "port = '5432'\n",
        "user = 'postgres'\n",
        "password = 'xxxxxx'\n",
        "database = 'walmart'"
      ],
      "metadata": {
        "id": "xwyFZCoboKFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#psql connection\n",
        "# \"pymysql://user:password@localhost:3306/db_name\"\n",
        "engine_psql = create_engine(\"postgresql+psycopg2://postgres:xxxxx@localhost:5432/walmart\")\n",
        "\n",
        "try:\n",
        "    engine_psql\n",
        "    print(\"Connection Successed to PSQL\")\n",
        "except:\n",
        "    print(\"Unable to connect\")"
      ],
      "metadata": {
        "id": "HdevcdM8xVWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating table at walmart database\n",
        "df_walmart.to_sql(name='walmart', con=engine_psql, if_exists='replace', index=False)"
      ],
      "metadata": {
        "id": "6rYCpBgXyPOV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}